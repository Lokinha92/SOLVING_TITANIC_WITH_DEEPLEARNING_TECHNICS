<h1 align='center'> SOLVING TITANIC WITH DEEP LEARNING TECHNICS </h1>

<strong><p align = center> GUSTAVO HENRIQUE D'ANUNCIA√á√ÉO FERREIRA</p></strong>

<h2 align = 'center'> ‚ùì Resumo </h2>

<b>Esta implementa√ß√£o prop√µe uma solu√ß√£o para o cl√°ssico problema de classifica√ß√£o do conjunto de dados do Titanic utilizando um modelo de Rede Neural Artificial.</b>

<h2 align = 'center'> üõ•Ô∏è O CONJUNTO DE DADOS DO TITANIC </h2>

O conjunto de dados do Titanic √© um conjunto de dados cl√°ssico amplamente utilizado em treinamento e aprendizado de m√°quina. Ele cont√©m informa√ß√µes sobre os passageiros do famoso navio RMS Titanic, que naufragou em sua viagem inaugural em 15 de abril de 1912, ap√≥s colidir com um iceberg. O conjunto de dados √© frequentemente usado para tarefas de classifica√ß√£o e an√°lise preditiva, especialmente para prever se um passageiro sobreviveu ou n√£o ao desastre.

O conjunto cont√©m informa√ß√µes sobre 891 passageiros do Titanic. As informa√ß√µes s√£o dividadas em 11 atributos diferentes e uma classe (Survived):

- PassengerId: Um identificador √∫nico para cada passageiro.
- Pclass (Classe): A classe do bilhete do passageiro (1¬™, 2¬™ ou 3¬™ classe).
- Name: Nome do passageiro.
- Sex: G√™nero do passageiro (masculino ou feminino).
- Age: Idade do passageiro.
- SibSp: (N√∫mero de Irm√£os/C√¥njuges a Bordo): Indica quantos irm√£os/c√¥njuges o passageiro tinha a bordo.
- Parch: (N√∫mero de Pais/Filhos a Bordo): Indica quantos pais/filhos o passageiro tinha a bordo.
- Ticket: N√∫mero do bilhete.
- Fare: (Tarifa): O valor pago pelo passageiro pela passagem.
- Cabin: (Cabine): O n√∫mero da cabine do passageiro.
- Embarked: (Local de Embarque): O local onde o passageiro embarcou (C = Cherbourg, Q = Queenstown, S = Southampton).
- Survived: Indica se o passageiro sobreviveu (1) ou n√£o (0) ao desastre.

Este √© o cabe√ßalho do conjunto de dados de treino:

<div align = center> <img align src = /img/trainhead.png> </div>

<h2 align = 'center'>üß©IMPLEMENTA√á√ÉO:</h2>

- As seguintes bibliotecas foram usadas durante a implementa√ß√£o:

```python
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from keras.models import Sequential
from keras.layers import Dense, Dropout, PReLU 
import matplotlib.pyplot as plt
import seaborn as sns
```

- Primeiramente, a leitura dos dados de treino √© feita, juntamente com um tratamento dos valores faltantes.

```python
caminho = "./drive/MyDrive/TITANIC/dados/train.csv"

train = pd.read_csv(caminho)

mediana = 28
train['Age'].fillna(mediana, inplace=True)

moda = SimpleImputer(missing_values=np.nan, strategy='most_frequent')
train.Cabin = moda.fit_transform(train[['Cabin']])

train['Embarked'].fillna('S', inplace=True)

train.info()
```

A vari√°vel caminho cont√©m o caminho para o arquivo contendo dados de treino, caso eles sejam movidos, o caminho deve ser atualizado.

O tratamento dos dados faltantes ocorre nos atributos 'Age', 'Cabin' e 'Embarked'. Ap√≥s o tratamento, o m√©todo ".info()" √© chamado para verificar se o tratamento ocorreu de forma correta.

<div align = center> <img align src = /img/info.png> </div>

O m√©todo info() retorna a tabela acima. Note que, n√£o h√° registros nulos em quaisquer colunas do dataset.

- A seguir, as vari√°veis categ√≥ricas que ser√£o usadas como atributos previsores s√£o tratadas com o LabelEncoder:

```python
label = LabelEncoder()

train['Sex'] = label.fit_transform(train['Sex'])

train['Embarked'] = label.fit_transform(train['Embarked'])
```

O LabelEncoder trata as vari√°veis categ√≥ricas para associar cada registro √∫nico a um n√∫mero inteiro.

- Nessa etapa, os atributos e a classe s√£o selecionados e armazenados nos objetos "atributos" e "classe", e os dados de treino e teste s√£o divididos tamb√©m.

```python
atributos = train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]

classe = train['Survived']

x_treino, x_teste, y_treino, y_teste = train_test_split(atributos, classe, test_size=0.3, random_state=0)
```

Neste caso, os dados de treino representam 70% dos dados, os outros 30% ficam para os dados de teste.

- Aqui, a ultima parte de pr√©-processamento dos dados de treino acontece:

```python
x_treino = tf.convert_to_tensor(x_treino, dtype=tf.float32)
y_treino = tf.convert_to_tensor(y_treino, dtype=tf.float32)
x_teste = tf.convert_to_tensor(x_teste, dtype=tf.float32)
y_teste = tf.convert_to_tensor(y_teste, dtype=tf.float32)

normalizador = StandardScaler()

x_treino = normalizador.fit_transform(x_treino)
x_teste = normalizador.fit_transform(x_teste)
```

Os dados de treino e teste s√£o convertidos para tensor_array, e o tipo de dados √© convertido para float32 para que a normaliza√ß√£o dos atributos de treino e teste com z-score aconte√ßa de forma correta.

- Finalmente, o modelo √© criado, configurado, compilado e treinado:

```python
rede = Sequential()

# 6 entradas -> 2 neuronios, 2 neuronios, 2 neuronios, 1 de sa√≠da pq √© binario

rede.add(Dense(units=2, kernel_initializer='uniform', input_dim=6))
rede.add(PReLU())  # Fun√ß√£o de ativa√ß√£o PReLU
rede.add(Dropout(0.2))
rede.add(Dense(units=2, kernel_initializer='uniform'))
rede.add(PReLU())  # Fun√ß√£o de ativa√ß√£o PReLU
rede.add(Dropout(0.2))
rede.add(Dense(units=2, kernel_initializer='uniform'))
rede.add(PReLU())  # Fun√ß√£o de ativa√ß√£o PReLU
rede.add(Dropout(0.2))

rede.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))

rede.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

rede.summary()

treinamento = rede.fit(x_treino, y_treino, batch_size=10 ,epochs=500, validation_data= (x_teste, y_teste))
```

A estrutura da rede √© formada por uma camada de entrada contendo 6 atributos, 3 camadas ocultas com 2 neur√¥nios cada e utilizam a fun√ß√£o de ativa√ß√£o PReLU.

Para a camada de sa√≠da, temos apenas 1 neur√¥nio, e a fun√ß√£o de ativa√ß√£o "sigmoid" √© utilizada, j√° que √© um problema de classifica√ß√£o bin√°ria.

Na fase de compila√ß√£o, o optimizador usado foi o 'adam', a fun√ß√£o de perda utilizada foi a 'binary_crossentropy' e o 'accuracy' foi usado para calcular as metricas de erro.

Enfim, a rede √© treinada atrav√©s do m√©todo .fit passando os dados de treino como os 2 primeiros hiperpar√¢metros e o n√∫mero de epochs (vezes que os dados s√£o submetidos √† RNA) pode ser alterado ajustando o hiperpar√¢metro "epochs". Como padr√£o, o n√∫mero de epochs foi definido como 500, mas o modelo pode ser treinado com qualquer n√∫mero de epochs.

N√£o √© necess√°rio criar um bloco de c√≥digo com o calculo das m√©tricas de erro, j√° que o modelo de RNA j√° faz esse calculo durante o treinamento, basta passar uma tupla contendo os dados de teste (respectivamente) para o hiperpar√¢metro "validation_data"

- As previsoes s√£o feitas. Depois, uma visualiza√ß√£o gr√°fica da performance do modelo no treinamento e a matriz de confus√£o com a performance das previs√µes s√£o mostradas.

```python
# previsoes

previsoes = rede.predict(x_teste)

previsoes = (previsoes > 0.55)
```

```python
# performance do modelo no treino

treinamento.history.keys()
plt.plot(treinamento.history['val_loss']) # evolu√ß√£o do erro azul

plt.plot(treinamento.history['val_accuracy'])

# matriz de confusao

confusao = confusion_matrix(y_teste, previsoes)

plt.figure(figsize=(8, 6))
sns.set(font_scale=1.2)
sns.heatmap(confusao, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Classe Predita')
plt.ylabel('Classe Real')
plt.title('Matriz de Confus√£o')
plt.show()
```

<div align = center> <img align src = /img/erro.png> </div>
<strong><p align = center> ERRO</p></strong>

<div align = center> <img align src = /img/confusao.png> </div>
<strong><p align = center> MATRIZ DE CONFUSAO</p></strong>


<h4 align = 'center'>SUBMETENDO O MODELO AOS DADOS DE TESTE</h4>

Os dados de teste tem a mesma estrutura dos dados de treino, com a √∫nica diferen√ßa de n√£o conter as informa√ß√µes a respeito da classe (Survived). Essa informa√ß√£o dever√° ser extra√≠da pelo nosso modelo utilizando as informa√ß√µes dadas pelos atributos dos dados de teste.

Eis o cabe√ßalho dos dados de teste:


<div align = center> <img align src = /img/testhead.png> </div>

- Primeiro o arquivo contendo os dados de teste √© lido, e, assim como nos dados de treino, um tratamento √© feito nos valores faltantes identificados:

```python
caminhoteste = "./dados/test.csv"

test = pd.read_csv(caminhoteste)

test['Age'].fillna(mediana, inplace=True)
test[['Cabin']] = moda.transform(test[['Cabin']])
test['Embarked'].fillna('S', inplace=True)
test['Fare'].fillna(test['Fare'].mean(), inplace=True)

test.info()
```

O m√©todo "info()" mostra que o tratamento ocorreu de forma correta:

<div align = center> <img align src = /img/infotest.png> </div>

Note que nenhum atributo acusa valores faltantes (NAN).

- O pr√©-processamento continua fazendo os mesmos tratamentos realizados no conjunto de treino, j√° que os dados de teste devem estar no mesmo formato dos dados de treino quando foram submetidos ao modelo no treinamento:

```python
labeltest = LabelEncoder()

test['Sex'] = labeltest.fit_transform(test['Sex'])
test['Embarked'] = labeltest.fit_transform(test['Embarked'])

atributosteste = test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]

atributosteste = atributosteste.values

atributosteste = tf.convert_to_tensor(atributosteste, dtype=tf.float32)

atributosteste = normalizador.fit_transform(atributosteste)
```

- Por fim, os dados de teste s√£o submetidos ao modelo:

```python
previsaoTeste = rede.predict(atributosteste)

previsaoTeste = (previsaoTeste > 0.55)
```
Como a previs√£o √© feita em termos de probabilidade, √© verificado se o valor da probabilidade prevista est√° acima de 55%, assim, √© estabelecido uma m√©trica para avaliar se a previs√£o ser√° an√°lisada como 0 (False) ou 1 (True).

<h2 align = center>üìà Resultados</h2>

Nesta parte, os resultados s√£o apresentados no formato de dataset, trazendo os atributos 'PassengerID' e 'Name' do conjunto 'test.csv' juntamente com o resultado da previsao, adicionada como um atributo chamado 'Survived'. O dataset de resultado √© gerado na pasta contendo o arquivo .py e se chama 'Resultado.csv'.

```python
previsaoTeste = previsaoTeste.flatten()
salvar = pd.DataFrame({'PassengerID': test['PassengerId'], 'Name': test['Name'], 'Survived': previsaoTeste})
salvar.to_csv('Resultado.csv', index=False)
```
O m√©todo ".flatten()" √© usado para transformar o array contendo as previs√µes em um array unidimensional, para que ele possa ser adicionado ao dataset no formato de coluna.

Eis o cabe√ßalho do arquivo 'Resultados.csv':


<div align = center> <img align src = /img/resulthead.png> </div>

<h2 align = center>üîß Compila√ß√£o e execu√ß√£o </h2>

Para compila√ß√£o e execu√ß√£o correta do c√≥digo, a vers√£o recomendada do Python √© a 3.8.x ou superiores.

Tamb√©m √© importante ressaltar que as bibliotecas devem estar instaladas corretamente no ambiente de execu√ß√£o, caso contr√°rio, erros v√£o ocorrer.